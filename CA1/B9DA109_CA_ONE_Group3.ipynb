{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Named Entity recognition with spaCy**\n",
        "---\n",
        "    Course - B9DA109: Machine Learning and Pattern Recognition\n",
        "---\n",
        "    Group No.3:\n",
        "    20066423 - Anish Rao\n",
        "    20054683 - Adithya Durgapu\n",
        "    20058721 - Phani Sri Pavansai Sharath Chandra Chavali Venkata\n",
        "---\n",
        "### Dataset - [BioCreative-V CDR Corpus](https://github.com/JHnlp/BioCreative-V-CDR-Corpus)\n",
        "---"
      ],
      "metadata": {
        "id": "vyigOP5gwepk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Project Goal & Approach**\n",
        "\n"
      ],
      "metadata": {
        "id": "QvBwo2-J8ZsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal**:\n",
        "> Develop an NER system capable of identifying entities in biomedical texts using active learning and rule-based techniques.\n",
        "\n",
        "**Approach**:\n",
        "> - Build a custom NLP pipeline using spaCy\n",
        "- Use spaCyâ€™s rule-based matching to create weak labels for training\n",
        "- Apply active learning to prioritize uncertain samples for labeling\n",
        "- Evaluate using precision/recall/F1 on test set"
      ],
      "metadata": {
        "id": "LIGY8bEvWfGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "yHPQc5VY7Fw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "collapsed": true,
        "id": "g6Ay1BDi_4aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c48bf05-851a-4344-f731-24e6a84a1b02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "import spacy\n",
        "from spacy.matcher import Matcher #more flexible than EntityRuler\n",
        "from spacy.scorer import Scorer\n",
        "from spacy.training import Example\n",
        "import spacy.util\n",
        "\n",
        "import warnings\n",
        "\n",
        "# load blank spacy model\n",
        "nlp = spacy.blank(\"en\")"
      ],
      "metadata": {
        "id": "0DHCvjp0wgei"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading & Parsing**"
      ],
      "metadata": {
        "id": "8fhO-8Mu7Tsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading"
      ],
      "metadata": {
        "id": "wkJCMJdWh1Du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"CDR_TrainingSet.PubTator.txt\"\n",
        "dev_path = \"CDR_DevelopmentSet.PubTator.txt\"\n",
        "test_path = \"CDR_TestSet.PubTator.txt\"\n",
        "\n",
        "def load_data(path):\n",
        "  \"\"\"\n",
        "  Reads and loads data from given file path.\n",
        "\n",
        "  Args:\n",
        "      path (str): The file path of the dataset.\n",
        "\n",
        "  Returns:\n",
        "      list: A list containing each line of the file as a string.\n",
        "  \"\"\"\n",
        "  with open(path, 'r', encoding='utf-8') as file:\n",
        "      data = file.readlines()\n",
        "  return data\n",
        "\n",
        "train_data = load_data(train_path)\n",
        "dev_data = load_data(dev_path)\n",
        "test_data = load_data(test_path)\n",
        "\n",
        "print(\"\\nSample Train Data:\\n\", train_data[:10])"
      ],
      "metadata": {
        "id": "uSlY_I9U-obt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8609f84c-b1c6-4f0f-e994-56e302fdc56c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Train Data:\n",
            " ['227508|t|Naloxone reverses the antihypertensive effect of clonidine.\\n', '227508|a|In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 micrograms/kg, was inhibited or reversed by nalozone, 0.2 to 2 mg/kg. The hypotensive effect of 100 mg/kg alpha-methyldopa was also partially reversed by naloxone. Naloxone alone did not affect either blood pressure or heart rate. In brain membranes from spontaneously hypertensive rats clonidine, 10(-8) to 10(-5) M, did not influence stereoselective binding of [3H]-naloxone (8 nM), and naloxone, 10(-8) to 10(-4) M, did not influence clonidine-suppressible binding of [3H]-dihydroergocryptine (1 nM). These findings indicate that in spontaneously hypertensive rats the effects of central alpha-adrenoceptor stimulation involve activation of opiate receptors. As naloxone and clonidine do not appear to interact with the same receptor site, the observed functional antagonism suggests the release of an endogenous opiate by clonidine or alpha-methyldopa and the possible role of the opiate in the central control of sympathetic tone.\\n', '227508\\t0\\t8\\tNaloxone\\tChemical\\tD009270\\n', '227508\\t49\\t58\\tclonidine\\tChemical\\tD003000\\n', '227508\\t93\\t105\\thypertensive\\tDisease\\tD006973\\n', '227508\\t181\\t190\\tclonidine\\tChemical\\tD003000\\n', '227508\\t244\\t252\\tnalozone\\tChemical\\t-1\\n', '227508\\t274\\t285\\thypotensive\\tDisease\\tD007022\\n', '227508\\t306\\t322\\talpha-methyldopa\\tChemical\\tD008750\\n', '227508\\t354\\t362\\tnaloxone\\tChemical\\tD009270\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Parsing"
      ],
      "metadata": {
        "id": "G-ZphaW7cUqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data(data):\n",
        "  \"\"\"\n",
        "  Parses PubTator formatted dataset to extract text and entity annotations.\n",
        "\n",
        "  Args:\n",
        "      data (list): List of lines from the dataset.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of tuples where each tuple contains:\n",
        "            - \"text\": The combined document text (title + abstract).\n",
        "            - \"entities\": A list of entity annotations as tuples\n",
        "                          (start, end, entity_type/label).\n",
        "  \"\"\"\n",
        "  with open(data, 'r', encoding='utf-8') as f:\n",
        "      text = f.read()\n",
        "\n",
        "  docs = []\n",
        "  current = {\"text\": \"\", \"entities\": []}\n",
        "\n",
        "  for line in text.split(\"\\n\"):\n",
        "      if line.startswith(\"#####\"):\n",
        "          continue\n",
        "      if \"|t|\" in line:\n",
        "          current[\"text\"] = line.split(\"|t|\")[-1].strip()\n",
        "      elif \"|a|\" in line:\n",
        "          current[\"text\"] += \" \" + line.split(\"|a|\")[-1].strip()\n",
        "      elif \"\\t\" in line:\n",
        "          parts = line.split(\"\\t\")\n",
        "          if len(parts) >= 5:\n",
        "              start, end, label = int(parts[1]), int(parts[2]), parts[4]\n",
        "              current[\"entities\"].append((start, end, label))\n",
        "      elif line.strip() == \"\" and current[\"text\"]:\n",
        "          docs.append(current)\n",
        "          current = {\"text\": \"\", \"entities\": []}\n",
        "\n",
        "  return docs # (\"Document text\", [(start1, end1, type1), (start2, end2, type2)])\n",
        "\n",
        "train = parse_data(train_path)\n",
        "dev = parse_data(dev_path)\n",
        "test = parse_data(test_path)\n",
        "\n",
        "train_dev = train + dev"
      ],
      "metadata": {
        "id": "4a1YEHBf6vtg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Viewing parsed documents"
      ],
      "metadata": {
        "id": "j2DHiZWKh9x4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display sample parsed documents\n",
        "print(\"\\nSample Parsed Documents:\")\n",
        "for i, doc in enumerate(train_dev[:1]):\n",
        "    print(f\"\\nDocument {i+1}:\")\n",
        "    print(\"Text:\", doc[\"text\"][:200] + \"...\")\n",
        "    print(\"Entities:\")\n",
        "    for start, end, label in doc[\"entities\"]:\n",
        "        entity_text = doc[\"text\"][start:end]\n",
        "        print(f\"  - {label}: '{entity_text}' (Position: {start}-{end})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdqbwf-v8PQ8",
        "outputId": "c775bc7d-588d-4db4-c98d-eb1c9296e027"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Parsed Documents:\n",
            "\n",
            "Document 1:\n",
            "Text: Naloxone reverses the antihypertensive effect of clonidine. In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 ...\n",
            "Entities:\n",
            "  - Chemical: 'Naloxone' (Position: 0-8)\n",
            "  - Chemical: 'clonidine' (Position: 49-58)\n",
            "  - Disease: 'hypertensive' (Position: 93-105)\n",
            "  - Chemical: 'clonidine' (Position: 181-190)\n",
            "  - Chemical: 'nalozone' (Position: 244-252)\n",
            "  - Disease: 'hypotensive' (Position: 274-285)\n",
            "  - Chemical: 'alpha-methyldopa' (Position: 306-322)\n",
            "  - Chemical: 'naloxone' (Position: 354-362)\n",
            "  - Chemical: 'Naloxone' (Position: 364-372)\n",
            "  - Disease: 'hypertensive' (Position: 469-481)\n",
            "  - Chemical: 'clonidine' (Position: 487-496)\n",
            "  - Chemical: '[3H]-naloxone' (Position: 563-576)\n",
            "  - Chemical: 'naloxone' (Position: 589-597)\n",
            "  - Chemical: 'clonidine' (Position: 637-646)\n",
            "  - Chemical: '[3H]-dihydroergocryptine' (Position: 671-695)\n",
            "  - Disease: 'hypertensive' (Position: 750-762)\n",
            "  - Chemical: 'naloxone' (Position: 865-873)\n",
            "  - Chemical: 'clonidine' (Position: 878-887)\n",
            "  - Chemical: 'clonidine' (Position: 1026-1035)\n",
            "  - Chemical: 'alpha-methyldopa' (Position: 1039-1055)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "_bgOCz6X9s56"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO"
      ],
      "metadata": {
        "id": "tS4EsIwy9zKU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Defining Rule-Based Matcher**"
      ],
      "metadata": {
        "id": "_qKNSgmy_zII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "chem_patterns = [\n",
        "    [{\"TEXT\": {\"REGEX\": \".*ol$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*ine$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*ide$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*ium$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*one$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*amine$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*ate$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*rin$\"}}],\n",
        "    [{\"LOWER\": {\"IN\": [\"acid\", \"salt\"]}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*azole$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*vir$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*dopa$\"}}],\n",
        "    # [{\"TEXT\": {\"REGEX\": \".*mab$\"}}]\n",
        "]\n",
        "\n",
        "disease_patterns = [\n",
        "    [{\"TEXT\": {\"REGEX\": \".*itis$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*osis$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*emia$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \".*opathy$\"}}],\n",
        "    # [{\"TEXT\": {\"REGEX\": \"^cardiac$\"}}, {\"TEXT\": {\"REGEX\": \"^asystole$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \"^heart$\"}}, {\"TEXT\": {\"REGEX\": \"^attack$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \"^myocardial$\"}}, {\"TEXT\": {\"REGEX\": \"^infarction$\"}}],\n",
        "    [{\"TEXT\": {\"REGEX\": \"^(AD|MS|ALS|HIV|AIDS|COVID)$\"}}],\n",
        "    # [{\"TEXT\": {\"REGEX\": \"^diabetes$\"}}],\n",
        "    [{\"LOWER\": {\"IN\": [\"disease\", \"syndrome\", \"cancer\"]}}],\n",
        "    [{\"LOWER\": {\"IN\": [\"infection\", \"fever\", \"headache\",\n",
        "                       \"tumor\", \"inflammation\"]}}],\n",
        "]\n",
        "\n",
        "matcher.add(\"CHEMICAL\", chem_patterns)\n",
        "matcher.add(\"DISEASE\", disease_patterns)\n",
        "\n",
        "\n",
        "def apply_rules(text):\n",
        "  \"\"\"\n",
        "  Applies the matcher to a text and sets the detected entities.\n",
        "\n",
        "  Args:\n",
        "      text (str): The input text to annotate.\n",
        "\n",
        "  Returns:\n",
        "      spacy.tokens.Doc: The processed doc with entities set.\n",
        "  \"\"\"\n",
        "  doc = nlp(text)\n",
        "  matches = matcher(doc)\n",
        "  spans = []\n",
        "  for match_id, start, end in matches:\n",
        "      label = nlp.vocab.strings[match_id]\n",
        "      span = spacy.tokens.Span(doc, start, end, label=label)\n",
        "      spans.append(span)\n",
        "  doc.ents = spans\n",
        "  return doc"
      ],
      "metadata": {
        "id": "BgxY9cVE_yyX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"The patient was administered naloxone and clonidine for cardiac asystole and diabetes. Ethanol is used to treat arthritis and leukemia. Swimming pools\"\n",
        "doc = apply_rules(test_text)\n",
        "\n",
        "matches = matcher(doc)\n",
        "print(\"\\nMatcher Results:\")\n",
        "for match_id, start, end in matches:\n",
        "    print(f\"{doc[start:end].text} - {nlp.vocab.strings[match_id]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yzt878VHxHi",
        "outputId": "46e02444-bec3-4074-caf0-e04c8314782c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matcher Results:\n",
            "naloxone - CHEMICAL\n",
            "clonidine - CHEMICAL\n",
            "Ethanol - CHEMICAL\n",
            "arthritis - DISEASE\n",
            "leukemia - DISEASE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Training Method**"
      ],
      "metadata": {
        "id": "bd9XIHGHDfiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_ner_model(model, data, n_iter=10):\n",
        "  \"\"\"\n",
        "  Trains a custom Named Entity Recognition (NER) model using spaCy.\n",
        "\n",
        "  Args:\n",
        "      model: The spaCy NLP model.\n",
        "      data: list of training examples as dictionary with \"text\" and \"entities\".\n",
        "      n_iter: Number of training iterations (epochs).\n",
        "\n",
        "  Returns:\n",
        "      None\n",
        "  \"\"\"\n",
        "  # Add the NER component if it does not exist in the model\n",
        "  if \"ner\" not in model.pipe_names:\n",
        "      ner = model.add_pipe(\"ner\", last=True)\n",
        "  else:\n",
        "      ner = model.get_pipe(\"ner\")\n",
        "\n",
        "  # Add entity labels to the NER component from the data\n",
        "  for doc_data in data:\n",
        "      for ent in doc_data[\"entities\"]:\n",
        "          label = ent[\"label\"] if isinstance(ent, dict) else ent[2]\n",
        "          try:\n",
        "              ner.add_label(label)\n",
        "          except Exception as e:\n",
        "              pass\n",
        "\n",
        "  # Prepare training examples in spaCy's required format\n",
        "  training_examples = []\n",
        "  for doc_data in data:\n",
        "      text = doc_data[\"text\"]\n",
        "      ents = []\n",
        "      for ent in doc_data[\"entities\"]:\n",
        "          if isinstance(ent, dict):\n",
        "              ents.append((ent[\"start\"], ent[\"end\"], ent[\"label\"]))\n",
        "          else:\n",
        "              ents.append(ent)\n",
        "      annotations = {\"entities\": ents}\n",
        "      training_examples.append(Example.from_dict(model.make_doc(text), annotations))\n",
        "\n",
        "  optimizer = model.begin_training()\n",
        "  for i in range(n_iter):\n",
        "      random.shuffle(training_examples)\n",
        "      losses = {}\n",
        "      batches = spacy.util.minibatch(training_examples, size=4)\n",
        "      for batch in batches:\n",
        "          model.update(batch, drop=0.5, sgd=optimizer, losses=losses)\n",
        "      print(f\"Iteration {i+1}, Loss: {losses.get('ner', 0):.4f}\")\n",
        "\n",
        "  print(\"\\nModel Training Completed!\")"
      ],
      "metadata": {
        "id": "cKG2d9DaDjC7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Uncertainty Sampling & Active Learning**"
      ],
      "metadata": {
        "id": "t7bW9bHmhMkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def uncertainty_sampling(model, data, n_samples=5):\n",
        "  \"\"\"\n",
        "  Uncertainty sampling by scoring documents based on the\n",
        "  inverse number of entities detected.\n",
        "\n",
        "  Args:\n",
        "      model: The trained spaCy model.\n",
        "      data: List of document dictionaries with \"text\" and \"entities\".\n",
        "      n_samples: Number of samples to select based on uncertainty.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of selected text samples with the highest uncertainty.\n",
        "  \"\"\"\n",
        "  scored_samples = []\n",
        "  for doc_data in data:\n",
        "      text = doc_data[\"text\"]\n",
        "      doc = model(text)\n",
        "      if len(doc.ents) == 0:\n",
        "          uncertainty_score = 1.0\n",
        "      else:\n",
        "          uncertainty_score = 1.0 / len(doc.ents)\n",
        "      scored_samples.append((text, uncertainty_score))\n",
        "\n",
        "  # Sort documents by uncertainty score in descending order\n",
        "  scored_samples.sort(key=lambda x: x[1], reverse=True)\n",
        "  return [sample[0] for sample in scored_samples[:n_samples]]\n",
        "\n",
        "\n",
        "\n",
        "def manual_annotation(text):\n",
        "  \"\"\"\n",
        "  Applying the matcher to the text.\n",
        "\n",
        "  Args:\n",
        "      text: The input text to annotate.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of dictionaries with keys\n",
        "            \"start\", \"end\", and \"label\" for each detected entity.\n",
        "  \"\"\"\n",
        "  doc = apply_rules(text)\n",
        "  return [{\"start\": ent.start_char, \"end\": ent.end_char, \"label\": ent.label_}\n",
        "          for ent in doc.ents]\n",
        "\n",
        "def active_learning_loop(model, data, iterations=3, n_samples=5):\n",
        "  \"\"\"\n",
        "  Runs an active learning loop to iteratively improve the model.\n",
        "\n",
        "  Args:\n",
        "      model (spacy.Language): The spaCy NLP model.\n",
        "      data (list): The training data (list of document dictionaries).\n",
        "      iterations (int): Number of active learning iterations.\n",
        "      n_samples (int): Number of uncertain samples to select in each iteration.\n",
        "\n",
        "  Returns:\n",
        "      None: The function updates the model and data in place.\n",
        "  \"\"\"\n",
        "  for i in range(iterations):\n",
        "    print(f\"\\nActive Learning Iteration {i+1}/{iterations}\")\n",
        "    # If not the first iteration, load the model from the previous iteration\n",
        "    if i > 0:\n",
        "        model = spacy.load(f\"model_iteration_{i}\")\n",
        "\n",
        "    # Select uncertain samples from the data based on uncertainty sampling\n",
        "    selected_texts = uncertainty_sampling(model, data, n_samples)\n",
        "    print(\"Selected uncertain samples for annotation:\")\n",
        "    for text in selected_texts:\n",
        "        print(\"  -\", text[:150] + \"...\")\n",
        "\n",
        "    # Annotate the selected samples using manual_annotation\n",
        "    new_annotations = []\n",
        "    for text in selected_texts:\n",
        "        annotated_entities = manual_annotation(text)\n",
        "        new_annotations.append({\"text\": text, \"entities\": annotated_entities})\n",
        "\n",
        "    # Update the training data with these new annotations\n",
        "    data.extend(new_annotations)\n",
        "    print(\"New annotations added.\")\n",
        "\n",
        "    # Retrain the model with the updated data\n",
        "    train_ner_model(model, data, n_iter=5)\n",
        "    model_path = f\"model_iteration_{i+1}\"\n",
        "    model.to_disk(model_path)\n",
        "\n",
        "  print(\"\\nActive Learning Loop Completed!\")"
      ],
      "metadata": {
        "id": "X4xiSqSnJ9ZT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "5xCRw-BVEcPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "lVRQo2drEhBR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.initialize()\n",
        "active_learning_loop(nlp, train_dev, iterations=3, n_samples=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXmDbLDzhcjF",
        "outputId": "de615158-320d-4517-8c49-5f68aebbb940"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Active Learning Iteration 1/3\n",
            "Selected uncertain samples for annotation:\n",
            "  - Naloxone reverses the antihypertensive effect of clonidine. In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 ...\n",
            "  - Lidocaine-induced cardiac asystole. Intravenous administration of a single 50-mg bolus of lidocaine in a 67-year-old man resulted in profound depression of the activity of the sinoatrial and atriovent...\n",
            "  - Suxamethonium infusion rate and observed fasciculations. A dose-response study. Suxamethonium chloride (Sch) was administered i.v. to 36 adult males at six rates: 0.25 mg s-1 to 20 mg s-1. The infusio...\n",
            "  - Galanthamine hydrobromide, a longer acting anticholinesterase drug, in the treatment of the central effects of scopolamine (Hyoscine). Galanthamine hydrobromide, an anticholinesterase drug capable of ...\n",
            "  - Effects of uninephrectomy and high protein feeding on lithium-induced chronic renal failure in rats. Rats with lithium-induced nephropathy were subjected to high protein (HP) feeding, uninephrectomy (...\n",
            "New annotations added.\n",
            "Iteration 1, Loss: 33701.4456\n",
            "Iteration 2, Loss: 18405.8793\n",
            "Iteration 3, Loss: 14333.0402\n",
            "Iteration 4, Loss: 12293.9230\n",
            "Iteration 5, Loss: 10711.3126\n",
            "\n",
            "Model Training Completed!\n",
            "\n",
            "Active Learning Iteration 2/3\n",
            "Selected uncertain samples for annotation:\n",
            "  - Time course alterations of QTC interval due to hypaque 76. Sequential measurement of QT interval during left ventricular angiography was made 30 seconds and one, three, five and ten minutes after inje...\n",
            "  - Magnetic resonance imaging of cerebral venous thrombosis secondary to \"low-dose\" birth control pills. The clinical and radiographic features of cerebral deep venous thrombosis in a 21-year-old white w...\n",
            "  - Angioedema due to ACE inhibitors: common and inadequately diagnosed. The estimated incidence of angioedema during angiotensin-converting enzyme (ACE) inhibitor treatment is between 1 and 7 per thousan...\n",
            "  - Recurarization in the recovery room. A case of recurarization in the recovery room is reported. Accumulation of atracurium in the intravenous line led to recurarization after flushing the line in the ...\n",
            "  - Influence of smoking on developing cochlea. Does smoking during pregnancy affect the amplitudes of transient evoked otoacoustic emissions in newborns? OBJECTIVE: Maternal tobacco smoking has negative ...\n",
            "New annotations added.\n",
            "Iteration 1, Loss: 35706.4786\n",
            "Iteration 2, Loss: 19335.6554\n",
            "Iteration 3, Loss: 14849.4650\n",
            "Iteration 4, Loss: 12598.2080\n",
            "Iteration 5, Loss: 10873.2381\n",
            "\n",
            "Model Training Completed!\n",
            "\n",
            "Active Learning Iteration 3/3\n",
            "Selected uncertain samples for annotation:\n",
            "  - Time course alterations of QTC interval due to hypaque 76. Sequential measurement of QT interval during left ventricular angiography was made 30 seconds and one, three, five and ten minutes after inje...\n",
            "  - Time course alterations of QTC interval due to hypaque 76. Sequential measurement of QT interval during left ventricular angiography was made 30 seconds and one, three, five and ten minutes after inje...\n",
            "  - Influence of smoking on developing cochlea. Does smoking during pregnancy affect the amplitudes of transient evoked otoacoustic emissions in newborns? OBJECTIVE: Maternal tobacco smoking has negative ...\n",
            "  - Magnetic resonance imaging of cerebral venous thrombosis secondary to \"low-dose\" birth control pills. The clinical and radiographic features of cerebral deep venous thrombosis in a 21-year-old white w...\n",
            "  - Magnetic resonance imaging of cerebral venous thrombosis secondary to \"low-dose\" birth control pills. The clinical and radiographic features of cerebral deep venous thrombosis in a 21-year-old white w...\n",
            "New annotations added.\n",
            "Iteration 1, Loss: 33034.2413\n",
            "Iteration 2, Loss: 19439.2181\n",
            "Iteration 3, Loss: 14554.2489\n",
            "Iteration 4, Loss: 12248.4358\n",
            "Iteration 5, Loss: 10932.6026\n",
            "\n",
            "Model Training Completed!\n",
            "\n",
            "Active Learning Loop Completed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation Metrics**"
      ],
      "metadata": {
        "id": "cSEZhL0bEh6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_data):\n",
        "  \"\"\"\n",
        "  Evaluates the trained NER model on the test data.\n",
        "\n",
        "  Args:\n",
        "      model (spacy.Language): The trained spaCy model.\n",
        "      test_data (list): The test data, a list of document dictionaries.\n",
        "\n",
        "  Returns:\n",
        "      tuple: A tuple containing precision, recall, and F1-score.\n",
        "  \"\"\"\n",
        "  y_true, y_pred = [], []\n",
        "\n",
        "  for doc_data in test_data:\n",
        "      text = doc_data[\"text\"]\n",
        "      # Create a set of gold standard entities from the test data\n",
        "      gold_entities = {(start, end, label) for start, end, label\n",
        "                       in doc_data[\"entities\"]}\n",
        "\n",
        "      doc = model(text)\n",
        "      # Create a set of entities predicted by the model\n",
        "      predicted_entities = {(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents}\n",
        "\n",
        "      # Track all possible labels\n",
        "      all_labels = set([ent[2] for ent in gold_entities]).union(set([ent[2] for ent in predicted_entities]))\n",
        "\n",
        "      # For each label, calculate true positives, false positives, and false negatives\n",
        "      for label in all_labels:\n",
        "          tp = len([e for e in gold_entities if e in predicted_entities and e[2] == label])\n",
        "          fp = len([e for e in predicted_entities if e not in gold_entities and e[2] == label])\n",
        "          fn = len([e for e in gold_entities if e not in predicted_entities and e[2] == label])\n",
        "\n",
        "          y_true.extend([label]*tp) # True positives: correct predictions\n",
        "          y_pred.extend([label]*tp)\n",
        "\n",
        "          y_true.extend([label]*fn) # False negatives: missing predictions\n",
        "          y_pred.extend([\"O\"]*fn)\n",
        "\n",
        "          y_true.extend([\"O\"]*fp) # False positives: extra predictions\n",
        "          y_pred.extend([label]*fp)\n",
        "\n",
        "  # Use micro average for entity-level metrics\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "      y_true, y_pred, average=\"micro\", labels=list(set(y_true) - {\"O\"})\n",
        "      )\n",
        "  print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n",
        "  return precision, recall, f1"
      ],
      "metadata": {
        "id": "MV56zohjEn9d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execution"
      ],
      "metadata": {
        "id": "RPWenUBSkscs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(nlp, test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBhPuWz4Sjmr",
        "outputId": "1b238b63-2609-4d90-d5e6-27de51426083"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.8299, Recall: 0.7322, F1-Score: 0.7780\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8299052461289577, 0.732184728310735, 0.7779884092509343)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion:**\n",
        "**Precision: 0.8299**\n",
        "\n",
        "When the model predicts an entity, there is about an 83% chance that the prediction is correct\n",
        "\n",
        "---\n",
        "**Recall: 0.7322**\n",
        "\n",
        "The model successfully identifies about 73% of the actual entities present in the text.\n",
        "\n",
        " Roughly 27% of the true entities are being missed.\n",
        "\n",
        "---\n",
        "**F1-Score: 0.7780**\n",
        "\n",
        "The F1-score is around 78%, reflecting a strong balance between prediction accuracy (precision) and entity capture (recall)."
      ],
      "metadata": {
        "id": "W7HypvBXhsZv"
      }
    }
  ]
}